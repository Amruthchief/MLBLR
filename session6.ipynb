{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 1st.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fuzz117/MLBLR/blob/master/session6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX7I-uSMhEGN",
        "colab_type": "code",
        "outputId": "ea1e3edc-0449-407f-edaf-dfab3160c80a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 131331 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.6-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.6-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.6-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPLpJzKpkJ7Q",
        "colab_type": "code",
        "outputId": "3a11d142-5543-4be0-8829-3b690da5f222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "\n",
        "import re\n",
        "import string\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIEuQ_nqld4d",
        "colab_type": "code",
        "outputId": "2c375a52-f278-4fd6-f4b3-83f77d4b0685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Larger LSTM Network to Generate Text for Alice in Wonderland\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXWoAyQnk5Uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"/content/gdrive/My Drive/Colab Notebooks/eip3p2/session6.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()\n",
        "raw_text = re.sub('['+string.punctuation+']', '', raw_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bfv1oyXvlzWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create mapping of unique chars to integers, and a reverse mapping\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts1vRmDqmHbx",
        "colab_type": "code",
        "outputId": "5b2ef690-e4f7-4db1-e580-f35541056367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \"), n_chars\n",
        "print (\"Total Vocab: \"), n_vocab\n",
        "print(chars)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters: \n",
            "Total Vocab: \n",
            "['\\n', ' ', '0', '3', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2dKwz1tmg2g",
        "colab_type": "code",
        "outputId": "01ccbd12-058c-4f50-a908-e6ce3fdcae40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \"), n_patterns"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 136016)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsslHer5m_wU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sekltZcCnC_p",
        "colab_type": "code",
        "outputId": "ae5e7389-9f9f-4de9-85d9-33037f6d7852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0722 17:22:28.131577 140134226470784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0722 17:22:28.167509 140134226470784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0722 17:22:28.174794 140134226470784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0722 17:22:28.480596 140134226470784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0722 17:22:28.489356 140134226470784 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0722 17:22:28.767660 140134226470784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0722 17:22:28.791642 140134226470784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcGcD1xUnNkE",
        "colab_type": "code",
        "outputId": "be396e39-4881-4c08-ba62-d89dd9e9aa68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 100, 256)          264192    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 30)                7710      \n",
            "=================================================================\n",
            "Total params: 797,214\n",
            "Trainable params: 797,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnIQpc2snngo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath=\"/content/gdrive/My Drive/Colab Notebooks/eip3p2/weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js5qPgV4oRKf",
        "colab_type": "code",
        "outputId": "0f24d0fb-a193-4091-f38d-678e5513d7a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "# fit the model\n",
        "model.fit(X, y, epochs=100, batch_size=1024, callbacks=callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "136016/136016 [==============================] - 54s 397us/step - loss: 1.3310 - acc: 0.6035\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.33105, saving model to /content/gdrive/My Drive/Colab Notebooks/eip3p2/weights.hdf5\n",
            "Epoch 2/100\n",
            "136016/136016 [==============================] - 53s 392us/step - loss: 1.3132 - acc: 0.6069\n",
            "\n",
            "Epoch 00002: loss improved from 1.33105 to 1.31318, saving model to /content/gdrive/My Drive/Colab Notebooks/eip3p2/weights.hdf5\n",
            "Epoch 3/100\n",
            "136016/136016 [==============================] - 54s 394us/step - loss: 1.2952 - acc: 0.6128\n",
            "\n",
            "Epoch 00003: loss improved from 1.31318 to 1.29522, saving model to /content/gdrive/My Drive/Colab Notebooks/eip3p2/weights.hdf5\n",
            "Epoch 4/100\n",
            "136016/136016 [==============================] - 54s 393us/step - loss: 1.2755 - acc: 0.6167\n",
            "\n",
            "Epoch 00004: loss improved from 1.29522 to 1.27552, saving model to /content/gdrive/My Drive/Colab Notebooks/eip3p2/weights.hdf5\n",
            "Epoch 5/100\n",
            "136016/136016 [==============================] - 54s 394us/step - loss: 1.2567 - acc: 0.6229\n",
            "\n",
            "Epoch 00005: loss improved from 1.27552 to 1.25674, saving model to /content/gdrive/My Drive/Colab Notebooks/eip3p2/weights.hdf5\n",
            "Epoch 6/100\n",
            "136016/136016 [==============================] - 54s 394us/step - loss: 1.2416 - acc: 0.6270\n",
            "\n",
            "Epoch 00006: loss improved from 1.25674 to 1.24159, saving model to /content/gdrive/My Drive/Colab Notebooks/eip3p2/weights.hdf5\n",
            "Epoch 7/100\n",
            "136016/136016 [==============================] - 53s 393us/step - loss: 1.2254 - acc: 0.6313\n",
            "\n",
            "Epoch 00007: loss improved from 1.24159 to 1.22538, saving model to /content/gdrive/My Drive/Colab Notebooks/eip3p2/weights.hdf5\n",
            "Epoch 8/100\n",
            "136016/136016 [==============================] - 54s 395us/step - loss: 1.2053 - acc: 0.6358\n",
            "\n",
            "Epoch 00008: loss improved from 1.22538 to 1.20533, saving model to /content/gdrive/My Drive/Colab Notebooks/eip3p2/weights.hdf5\n",
            "Epoch 9/100\n",
            " 98304/136016 [====================>.........] - ETA: 14s - loss: 1.1852 - acc: 0.6419"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goi0F8QEn3nB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "190079b5-1a10-4dee-8feb-ad2f455d9326"
      },
      "source": [
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(500):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tprint(result,end='')\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" ou and listen to me ill soon make you\n",
            "dry enough they all sat down at once in a large ring with the  \"\n",
            "gryphon and the thoe the mouse was a little sime way of the sea the king and the mouse was so she said to herself the mock turtle seemed to herself the mock turtle seemed to herself the mock turtle seemed to herself the mock turtle seemed to herself the mock turtle seemed to herself the mock turtle seemed to herself the mock turtle seemed to herself the mock turtle seemed to herself the mock turtle seemed to herself the mock turtle seemed to herself the mock turtle seemed to herself the mock tur\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}