{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fuzz117/MLBLR/blob/master/session5ass.ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSUhmTQZ0tsr",
        "colab_type": "code",
        "outputId": "4317ca74-2970-48f7-bc4e-7ee464e5722f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
        "epochs = 100\n",
        "data_augmentation = True\n",
        "num_classes = 10\n",
        "\n",
        "# Subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "# Model parameter\n",
        "# ----------------------------------------------------------------------------\n",
        "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
        "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
        "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
        "# ----------------------------------------------------------------------------\n",
        "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
        "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
        "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
        "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
        "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
        "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
        "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
        "# ---------------------------------------------------------------------------\n",
        "n = 3\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "version = 1\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "\n",
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n",
        "\n",
        "\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# Run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "  \n",
        "\n",
        "    \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0702 06:19:36.044619 139830753003392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0702 06:19:36.054711 139830753003392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0702 06:19:36.058467 139830753003392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "W0702 06:19:36.085033 139830753003392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0702 06:19:36.086020 139830753003392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0702 06:19:36.806105 139830753003392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0702 06:19:38.548897 139830753003392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "W0702 06:19:38.586089 139830753003392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               \n",
            "                                                                 batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 32)   4640        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 32)   9248        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 32)   544         activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 32)   0           conv2d_10[0][0]                  \n",
            "                                                                 batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 32)   0           activation_9[0][0]               \n",
            "                                                                 batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 32)   9248        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 32)   0           activation_11[0][0]              \n",
            "                                                                 batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 64)     18496       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 64)     36928       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 64)     2112        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 64)     0           conv2d_17[0][0]                  \n",
            "                                                                 batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 64)     0           activation_15[0][0]              \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 8, 8, 64)     36928       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 8, 8, 64)     0           activation_17[0][0]              \n",
            "                                                                 batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v1\n",
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mduemjkQyCul",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "08b27d59-3659-48b8-cb5d-608da497d539"
      },
      "source": [
        "new_model = keras.models.load_model('drive/Colab Notebooks/eip3p2/session5.h5')\n",
        "scores = new_model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0702 06:19:43.501634 139830753003392 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 382us/step\n",
            "Test loss: 0.47059100766181944\n",
            "Test accuracy: 0.9056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2MszTKs_ziS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred =  new_model.predict(x_test)\n",
        "# print(y_pred[9002].argmax())\n",
        "# print(y_test[9002].argmax())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sve6v-WLBoJl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7589f815-fafd-472f-e760-0936f8f98d0e"
      },
      "source": [
        "\n",
        "numberofincorrect = 0\n",
        "incorrectpos = []\n",
        "for i in range(0,10000):\n",
        "    if(y_pred[i].argmax() != y_test[i].argmax()):\n",
        "#         print(\"POS \",i)\n",
        "#         print(\"y_pred \",y_pred[i].argmax())\n",
        "#         print(\"y_test \",y_test[i])\n",
        "#         print(\" f u \")\n",
        "        numberofincorrect = numberofincorrect + 1 \n",
        "        incorrectpos.append(i)\n",
        "        \n",
        "print(\"numberofincorrect \",numberofincorrect)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numberofincorrect  944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-byE4PhAHgYS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "6cd9e3f3-3a9a-4758-8581-fa6cbcf618f4"
      },
      "source": [
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "plt.imshow(x_test[incorrectpos[0]])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0702 06:19:53.998735 139830753003392 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2c32ddbbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyU8UKCY/UaCY/ESBYvITBer/AfbyNPh0GBFhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc1oSfS0leMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import  preprocess_input, decode_predictions\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import cv2\n",
        "from skimage import io\n",
        "# for i in range(0,50)\n",
        "dog= x_test[incorrectpos[0]]\n",
        "dog = cv2.resize(x_test[incorrectpos[0]], dsize=(32,32), interpolation=cv2.INTER_CUBIC)\n",
        "x = image.img_to_array(dog)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K2rP0M7lqna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preds = new_model.predict(x)\n",
        "# class_idx = np.argmax(preds[0])\n",
        "# print(class_idx)\n",
        "# class_output = model.output[:, class_idx]\n",
        "\n",
        "\n",
        "# last_conv_layer = model.get_layer(\"conv2d_21\")\n",
        "# grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
        "# print(grads.shape)\n",
        "\n",
        "# pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "# print(pooled_grads.shape)\n",
        "# iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "\n",
        "# pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "\n",
        "# for i in range(64):\n",
        "#   conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
        "  \n",
        "#   heatmap = np.mean(conv_layer_output_value, axis = -1)\n",
        "\n",
        "# print(conv_layer_output_value.shape)\n",
        "# print(heatmap.shape)\n",
        "# heatmap = np.maximum(heatmap, 0)\n",
        "# heatmap /= np.max(heatmap)\n",
        "# heatmap = cv2.resize(heatmap, (dog.shape[1], dog.shape[0]))\n",
        "# heatmap = np.uint8(255 * heatmap)\n",
        "# heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "# # superimposed_img = cv2.addWeighted(dog, 0.5, heatmap, 0.5, 0)\n",
        "# from google.colab.patches import cv2_imshow\n",
        "# cv2_imshow(dog)\n",
        "# cv2_imshow(heatmap)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7x2w2KeR5F7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "3e60039e-efd1-4368-fcfd-c6f0c44ad316"
      },
      "source": [
        "from keras.applications.vgg16 import  preprocess_input, decode_predictions\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import cv2\n",
        "from skimage import io\n",
        "dog= x_test[incorrectpos[0]]\n",
        "dog = cv2.resize(dog, dsize=(32,32), interpolation=cv2.INTER_CUBIC)\n",
        "x = image.img_to_array(dog)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = new_model.predict(x)\n",
        "class_idx = np.argmax(preds[0])\n",
        "print(class_idx)\n",
        "class_output = model.output[:, class_idx]\n",
        "last_conv_layer = model.get_layer(\"conv2d_21\")\n",
        "\n",
        "\n",
        "grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
        "print(grads.shape)\n",
        "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "print(pooled_grads.shape)\n",
        "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "\n",
        "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "\n",
        "for i in range(64):\n",
        "  conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
        "  \n",
        " \n",
        "\n",
        "heatmap = np.mean(conv_layer_output_value, axis = -1)\n",
        "print(conv_layer_output_value.shape)\n",
        "print(heatmap.shape)\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap /= np.max(heatmap)\n",
        "\n",
        "\n",
        "heatmap = cv2.resize(heatmap, (dog.shape[1], dog.shape[0]))\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "#superimposed_img = cv2.addWeighted(dog, 0.5, heatmap, 0.5, 0)\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(dog)\n",
        "cv2_imshow(heatmap)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "(?, 8, 8, 64)\n",
            "(64,)\n",
            "(8, 8, 64)\n",
            "(8, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAGUlEQVR4nO3BMQEAAADCoPVP7WEN\noAAAAG4MIAABt9NlCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F2C01225278>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAKUlEQVR4nO3NMQEAAAjDsIFypGMC\nvlRAU8nks369AwAAAAAAAAAAgMMWnwkAwH+RaUUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F2C012915C0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_gxrvgAOQ5H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "e89c3476-a181-4083-d8ac-c2bce038282f"
      },
      "source": [
        "\n",
        "plt.imshow(dog)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0702 06:19:55.295743 139830753003392 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2c009d7080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7dkL0jOOcDJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "409e2058-8898-4410-8c3e-64083f336c7a"
      },
      "source": [
        "plt.imshow(heatmap)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2c00935b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGb/U1P8CTqgDJhHbDnUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-EPeaVKx0BR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "ba5f758d-c4b9-471a-f2b6-c8f0a2ff1acb"
      },
      "source": [
        "# from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.imshow(x_test[incorrectpos[9]])\n",
        "print(y_test[incorrectpos[9]])\n",
        "\n",
        "print(y_pred[incorrectpos[9]])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0702 06:19:55.644895 139830753003392 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "[6.20155333e-05 9.91615700e-04 1.40070197e-05 9.74212408e-01\n",
            " 1.37448005e-05 1.41136749e-02 9.17569268e-03 2.78067018e-05\n",
            " 2.24964879e-05 1.36650342e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOOjVTaqx7eN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "outputId": "a0d4d05a-ba86-4712-99de-216402f6a092"
      },
      "source": [
        "images=x_test[0:100]\n",
        "cls_true= x_test[0:100]\n",
        "plt.imshow(cls_true)\n",
        "# plt(images=images, cls_true=cls_true,smooth=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-cdd326c21d49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcls_true\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# plt(images=images, cls_true=cls_true,smooth=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2698\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2699\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2700\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2701\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5492\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5494\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5495\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    636\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    637\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNYZBUmMYJDWGQVJjGCQ1/wMKpFHVdp3xCwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}