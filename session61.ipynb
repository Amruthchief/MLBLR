{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fuzz117/MLBLR/blob/Fuzz117%2FMLBLR%2Fnew/session61.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPLpJzKpkJ7Q",
        "colab_type": "code",
        "outputId": "7dfafdce-6220-49e9-d415-af4aef6ed412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "\n",
        "import re\n",
        "import string\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIEuQ_nqld4d",
        "colab_type": "code",
        "outputId": "00ba39aa-e5f6-4cdb-f447-5e2990aace1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Larger LSTM Network to Generate Text for Alice in Wonderland\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXWoAyQnk5Uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"/content/gdrive/My Drive/Colab Notebooks/session6/text.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()\n",
        "raw_text = re.sub('['+string.punctuation+']', '', raw_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bfv1oyXvlzWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create mapping of unique chars to integers, and a reverse mapping\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts1vRmDqmHbx",
        "colab_type": "code",
        "outputId": "a01b8bbf-aecb-4c08-aef7-7c340111bf66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \"), n_chars\n",
        "print (\"Total Vocab: \"), n_vocab\n",
        "print(chars)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters: \n",
            "Total Vocab: \n",
            "['\\n', ' ', '0', '3', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2dKwz1tmg2g",
        "colab_type": "code",
        "outputId": "83c3060f-c8a6-43a2-f5f7-90fe70de8f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \"), n_patterns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 136016)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsslHer5m_wU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sekltZcCnC_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(256))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcGcD1xUnNkE",
        "colab_type": "code",
        "outputId": "a1c00f8d-cc58-475d-b1dd-b7d4d540d558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 100, 256)          264192    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 30)                7710      \n",
            "=================================================================\n",
            "Total params: 797,214\n",
            "Trainable params: 797,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnIQpc2snngo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath=\"/content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js5qPgV4oRKf",
        "colab_type": "code",
        "outputId": "3e1bb224-8056-40a6-f635-3d37a85bc9da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# fit the model\n",
        "model.fit(X, y, epochs=100, batch_size=512, callbacks=callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "136016/136016 [==============================] - 74s 543us/step - loss: 2.8883 - acc: 0.1816\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.88835, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 2/100\n",
            "136016/136016 [==============================] - 72s 531us/step - loss: 2.7921 - acc: 0.2105\n",
            "\n",
            "Epoch 00002: loss improved from 2.88835 to 2.79212, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 3/100\n",
            "136016/136016 [==============================] - 72s 527us/step - loss: 2.5705 - acc: 0.2697\n",
            "\n",
            "Epoch 00003: loss improved from 2.79212 to 2.57049, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 4/100\n",
            "136016/136016 [==============================] - 72s 533us/step - loss: 2.3934 - acc: 0.3093\n",
            "\n",
            "Epoch 00004: loss improved from 2.57049 to 2.39340, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 5/100\n",
            "136016/136016 [==============================] - 72s 530us/step - loss: 2.2417 - acc: 0.3458\n",
            "\n",
            "Epoch 00005: loss improved from 2.39340 to 2.24167, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 6/100\n",
            "136016/136016 [==============================] - 72s 527us/step - loss: 2.1234 - acc: 0.3785\n",
            "\n",
            "Epoch 00006: loss improved from 2.24167 to 2.12340, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 7/100\n",
            "136016/136016 [==============================] - 72s 527us/step - loss: 2.0298 - acc: 0.4073\n",
            "\n",
            "Epoch 00007: loss improved from 2.12340 to 2.02979, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 8/100\n",
            "136016/136016 [==============================] - 73s 533us/step - loss: 1.9510 - acc: 0.4314\n",
            "\n",
            "Epoch 00008: loss improved from 2.02979 to 1.95102, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 9/100\n",
            "136016/136016 [==============================] - 72s 531us/step - loss: 1.8823 - acc: 0.4521\n",
            "\n",
            "Epoch 00009: loss improved from 1.95102 to 1.88226, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 10/100\n",
            "136016/136016 [==============================] - 72s 526us/step - loss: 1.8244 - acc: 0.4671\n",
            "\n",
            "Epoch 00010: loss improved from 1.88226 to 1.82437, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 11/100\n",
            "136016/136016 [==============================] - 71s 525us/step - loss: 1.7753 - acc: 0.4812\n",
            "\n",
            "Epoch 00011: loss improved from 1.82437 to 1.77531, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 12/100\n",
            "136016/136016 [==============================] - 72s 528us/step - loss: 1.7310 - acc: 0.4935\n",
            "\n",
            "Epoch 00012: loss improved from 1.77531 to 1.73104, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 13/100\n",
            "136016/136016 [==============================] - 72s 528us/step - loss: 1.6907 - acc: 0.5044\n",
            "\n",
            "Epoch 00013: loss improved from 1.73104 to 1.69065, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 14/100\n",
            "136016/136016 [==============================] - 72s 526us/step - loss: 1.6550 - acc: 0.5151\n",
            "\n",
            "Epoch 00014: loss improved from 1.69065 to 1.65503, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 15/100\n",
            "136016/136016 [==============================] - 71s 525us/step - loss: 1.6199 - acc: 0.5235\n",
            "\n",
            "Epoch 00015: loss improved from 1.65503 to 1.61994, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 16/100\n",
            "136016/136016 [==============================] - 71s 523us/step - loss: 1.5876 - acc: 0.5330\n",
            "\n",
            "Epoch 00016: loss improved from 1.61994 to 1.58762, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 17/100\n",
            "136016/136016 [==============================] - 72s 527us/step - loss: 1.5588 - acc: 0.5405\n",
            "\n",
            "Epoch 00017: loss improved from 1.58762 to 1.55879, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 18/100\n",
            "136016/136016 [==============================] - 71s 524us/step - loss: 1.5310 - acc: 0.5475\n",
            "\n",
            "Epoch 00018: loss improved from 1.55879 to 1.53095, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 19/100\n",
            "136016/136016 [==============================] - 71s 524us/step - loss: 1.5014 - acc: 0.5549\n",
            "\n",
            "Epoch 00019: loss improved from 1.53095 to 1.50143, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 20/100\n",
            "136016/136016 [==============================] - 71s 525us/step - loss: 1.4794 - acc: 0.5614\n",
            "\n",
            "Epoch 00020: loss improved from 1.50143 to 1.47940, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 21/100\n",
            "136016/136016 [==============================] - 72s 527us/step - loss: 1.4538 - acc: 0.5692\n",
            "\n",
            "Epoch 00021: loss improved from 1.47940 to 1.45385, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 22/100\n",
            "136016/136016 [==============================] - 71s 523us/step - loss: 1.4302 - acc: 0.5745\n",
            "\n",
            "Epoch 00022: loss improved from 1.45385 to 1.43015, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 23/100\n",
            "136016/136016 [==============================] - 71s 525us/step - loss: 1.4060 - acc: 0.5829\n",
            "\n",
            "Epoch 00023: loss improved from 1.43015 to 1.40599, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 24/100\n",
            "136016/136016 [==============================] - 71s 525us/step - loss: 1.3870 - acc: 0.5865\n",
            "\n",
            "Epoch 00024: loss improved from 1.40599 to 1.38700, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 25/100\n",
            "136016/136016 [==============================] - 72s 529us/step - loss: 1.3649 - acc: 0.5927\n",
            "\n",
            "Epoch 00025: loss improved from 1.38700 to 1.36489, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 26/100\n",
            "136016/136016 [==============================] - 71s 524us/step - loss: 1.3446 - acc: 0.5977\n",
            "\n",
            "Epoch 00026: loss improved from 1.36489 to 1.34461, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 27/100\n",
            "136016/136016 [==============================] - 71s 524us/step - loss: 1.3248 - acc: 0.6034\n",
            "\n",
            "Epoch 00027: loss improved from 1.34461 to 1.32476, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 28/100\n",
            "136016/136016 [==============================] - 71s 524us/step - loss: 1.3032 - acc: 0.6096\n",
            "\n",
            "Epoch 00028: loss improved from 1.32476 to 1.30325, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 29/100\n",
            "136016/136016 [==============================] - 71s 524us/step - loss: 1.2831 - acc: 0.6152\n",
            "\n",
            "Epoch 00029: loss improved from 1.30325 to 1.28306, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 30/100\n",
            "136016/136016 [==============================] - 71s 524us/step - loss: 1.2641 - acc: 0.6202\n",
            "\n",
            "Epoch 00030: loss improved from 1.28306 to 1.26411, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 31/100\n",
            "136016/136016 [==============================] - 71s 520us/step - loss: 1.2459 - acc: 0.6259\n",
            "\n",
            "Epoch 00031: loss improved from 1.26411 to 1.24587, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 32/100\n",
            "136016/136016 [==============================] - 71s 521us/step - loss: 1.2280 - acc: 0.6305\n",
            "\n",
            "Epoch 00032: loss improved from 1.24587 to 1.22797, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 33/100\n",
            "136016/136016 [==============================] - 71s 521us/step - loss: 1.2085 - acc: 0.6351\n",
            "\n",
            "Epoch 00033: loss improved from 1.22797 to 1.20853, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 34/100\n",
            "136016/136016 [==============================] - 73s 533us/step - loss: 1.1930 - acc: 0.6402\n",
            "\n",
            "Epoch 00034: loss improved from 1.20853 to 1.19296, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 35/100\n",
            "136016/136016 [==============================] - 71s 523us/step - loss: 1.1743 - acc: 0.6447\n",
            "\n",
            "Epoch 00035: loss improved from 1.19296 to 1.17426, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 36/100\n",
            "136016/136016 [==============================] - 72s 530us/step - loss: 1.1572 - acc: 0.6504\n",
            "\n",
            "Epoch 00036: loss improved from 1.17426 to 1.15723, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 37/100\n",
            "136016/136016 [==============================] - 71s 523us/step - loss: 1.1435 - acc: 0.6530\n",
            "\n",
            "Epoch 00037: loss improved from 1.15723 to 1.14346, saving model to /content/gdrive/My Drive/Colab Notebooks/session6/weights6.hdf5\n",
            "Epoch 38/100\n",
            " 72704/136016 [===============>..............] - ETA: 32s - loss: 1.1095 - acc: 0.6658"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goi0F8QEn3nB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(500):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tprint(result,end='')\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}